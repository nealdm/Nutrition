{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation and Overview of Data:\n",
    "\n",
    "## Project Purpose:\n",
    "\n",
    "There is alot of unknown flexability when it comes to recipes.  When you open up a recipe in a book, it is hard to know what leaneancy you have.\n",
    "\n",
    "We want to compare recipies of different types to find trends in their nutritional value.  We hope that by creating a \n",
    "\n",
    "## Questions to Answer:\n",
    "\n",
    "\n",
    "## Background knowledge/resources: \n",
    "Talk about what has been done, and what this will cover that is different.\n",
    "\n",
    "this is a secret edit\n",
    "\n",
    "## Data overview:\n",
    "Talk about what the data looks like before we talk about how we got it (don't walk them through the cleaning process; walk them through what they will see, then talk about how we got it/cleaned it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning:\n",
    "\n",
    "## Collection Procedure:\n",
    "talk about how data is used at each step:\n",
    "\n",
    "The recipe website divided its recipies into categories. Some examples of these are: Chili, Lamb, Potatoes, and even Christmas recipes!\n",
    "The code to scrape this website divides into 4 functions.\n",
    "\n",
    "- first one gets the links on the main site\n",
    "- Then we separate them into categories\n",
    "- We then collect the recipes\n",
    "- And we parse through them\n",
    "\n",
    "![title](example_recipe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the individual ingredients we can start collecting nutritional data. The site that we used is okay with us using their data as long as we are not going to sell it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaper we built for this task searches each ingredient on nutritionvalue.org and takes the first available 3 links. The reason for this is that the top link might not be what we are looking for but, since they are ordered by relevance, it is highly likely to be on the top three.\n",
    "\n",
    "Example of query with Oats:\n",
    "![title](nutrition_value_query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These links are collected in a dictionary with the ingredient as its respective value. The code is able to handle common errors like \"no results\", \"less than 3 links\", and \"can't find search bar.\n",
    "\n",
    "code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE: Scraper 1\n",
    "def nutrition_website(ingredients):\n",
    "    \"\"\"Use Selenium to enter the given search query into the search bar of\n",
    "    nutrion website and gets links to scrape data\n",
    "\n",
    "    Returns:\n",
    "        (dictonary): urls .\n",
    "    \"\"\"\n",
    "    #initialize variables and chrome\n",
    "    ingredients_dictionary = {}\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.nutritionvalue.org/\")\n",
    "    num_links = 3\n",
    "    try:\n",
    "        for i in ingredients:\n",
    "            try:\n",
    "                #navigate\n",
    "                search_bar = browser.find_element_by_name('food_query')\n",
    "                search_bar.clear()\n",
    "                search_bar.send_keys(Keys.CONTROL + \"a\")\n",
    "                search_bar.send_keys(Keys.DELETE)\n",
    "                search_bar.send_keys(i)\n",
    "\n",
    "                search_bar.send_keys(Keys.RETURN)\n",
    "                \n",
    "                words = i.split()\n",
    "                x = \"\"\n",
    "                for n,w in enumerate(words):\n",
    "                    if n == 0:\n",
    "                        x += \".*(?<!food_query=)\"+w+\".*|\"\n",
    "                    else:\n",
    "                        x += \".*(?<!\\+)\"+w+\".*|\"\n",
    "                x = x[:-1]\n",
    "                find = re.compile(x,re.IGNORECASE)\n",
    "            \n",
    "                \n",
    "                # wait for page to load\n",
    "                time.sleep(2)\n",
    "                currentURL = browser.current_url\n",
    "                if \"food_query\" in currentURL:\n",
    "                    \n",
    "                    links = browser.find_elements_by_tag_name('a')\n",
    "                    links = [link.get_attribute(\"href\") for link in links if isinstance(link.get_attribute(\"href\"),str)]\n",
    "                    urls = [link for link in links if len(find.findall(link)) > 0]\n",
    "                    if len(urls) >num_links:\n",
    "                        ingredients_dictionary[i] = urls[:num_links]\n",
    "                    elif len(urls) == 0:\n",
    "                        ingredients_dictionary[i] = None\n",
    "                    else:\n",
    "                        ingredients_dictionary[i] = urls\n",
    "                else:\n",
    "                    ingredients_dictionary[i] = [currentURL]\n",
    "                \n",
    "\n",
    "            except NoSuchElementException:\n",
    "                print(\"could not find the search bar!\")\n",
    "                print(i)\n",
    "                return ingredients_dictionary\n",
    "    # close window\n",
    "    finally:\n",
    "        browser.close()\n",
    "    # list with all the links\n",
    "    return ingredients_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nutrition Values\n",
    "\n",
    "Now we are ready to get the nutritional value.\n",
    "\n",
    "Each ingredient link contains tables of nutritonal properties and their quantities. Here is an example of the content of the link related to \"Oats\".\n",
    "\n",
    "![](nutrition_values_oats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaper will go through the dictionary of links and collect the name, serving size, macronutries (Protein, fat, carbohydrates), micronutrients (vitamins and minerals), and any other fact on the tables available.\n",
    "\n",
    "The code prints out any links that cause an error to help minimize the number of missing ingredients. There were a few links with error but we inspected them and made sure we weren't losing any important information. They turned out to be links that were not related to food but rather other parts of the website that were at times included in our query. \n",
    "\n",
    "In order to not abuse the websites information we also added an argument that skips the search if it has already been pulled.\n",
    "\n",
    "code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for scraper\n",
    "def nutrition_value(dictionary,set_of_links = set()):\n",
    "    \"\"\"Takes in a dictionary with ingredients as keys\n",
    "    look through the websites and scrape the nutritional value\"\"\"\n",
    "    error_items =[]\n",
    "    df_d = dict()\n",
    "    browser = webdriver.Chrome()\n",
    "    try:\n",
    "        for k,v in zip(dictionary.keys(),dictionary.values()):\n",
    "            if v is None:\n",
    "                df_d[k] = {}\n",
    "            else:    \n",
    "                for l in v:\n",
    "                    try:\n",
    "                        if l is None:\n",
    "                            print(f\"No Website for: {k}\")\n",
    "                        elif l in set_of_links:\n",
    "                            print(f\"Duplicates for {k}\")\n",
    "                        else:\n",
    "                            browser.get(l)\n",
    "                            time.sleep(5)\n",
    "                            # name of ingredient\n",
    "                            name = browser.find_elements_by_tag_name('h1')[0]\n",
    "                            name = name.text\n",
    "\n",
    "                            #setting up nutritional values\n",
    "                            nut = dict()\n",
    "                            c = \"tbody\"\n",
    "                            tables = browser.find_elements_by_tag_name(c)\n",
    "                            #### For essentials [4]\n",
    "                            ser_cal = tables[4].text.split('\\n')\n",
    "                            # Serving Size\n",
    "                            nut[ser_cal[1][:12]] = ser_cal[1][13:]\n",
    "                            #Calories\n",
    "                            nut[ser_cal[3][:8]] = ser_cal[3][9:]\n",
    "\n",
    "                            #### For all others [7-13]\n",
    "                            n_v = re.compile('\\s*(.*)\\s([0-9]+\\.[0-9]+\\s\\w+)')\n",
    "                            for i in range(7,14):\n",
    "                                nutrient_value = [n_v.findall(t) for t in tables[i].text.split('\\n') if len(t) >0]\n",
    "                                for t in nutrient_value:\n",
    "                                    if len(t)>0:\n",
    "                                        nut[t[0][0]] = t[0][1]\n",
    "\n",
    "                            df_d[name] = nut\n",
    "                            set_of_links.add(l)\n",
    "                        \n",
    "                    except IndexError as e:\n",
    "                        error_items.append(k)\n",
    "                        print(f\"ingredient:{k}, error: {e}, link: {l}\")\n",
    "                    except:\n",
    "                        error_items.append(k)\n",
    "                        print(f\"ingredient:{k}, error: IDK, link: {l}\")\n",
    "            \n",
    "    finally:\n",
    "        browser.close()\n",
    "    # list with all the links\n",
    "    df = pd.DataFrame.from_dict(df_d,'index')\n",
    "    return df, error_items, set_of_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Nutritional Data\n",
    "\n",
    "Once we collected the data we analyzed it for errors. There were two columns that had only one value out of all the ingredients - the number \"18\" and \"adjusted Protein\". For this reason we dropped those columns. \n",
    "\n",
    "The rest of the data was cleaned by making all values floats, converting values to grams (g) and making serving sizes be 1g for all ingredients.\n",
    "\n",
    "Vitamin A and D were a special case because they were measured in International Units (IU) so we converted them to grams\n",
    "\n",
    "Lastly, we engineered a columns for all minerals and vitamins for future investigation of trends in nutrition - Whether you can get all the nutrition you need from certain foods or recipes.\n",
    "\n",
    "This is our nutrtional_value dataframe\n",
    "\n",
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floats for calories\n",
    "df = ds\n",
    "df[\"Calories\"] = df['Calories'].astype('float')/100\n",
    "df = df.drop(columns = [\"18\",\"Adjusted Protein\"]) # contains singleton\n",
    "\n",
    "for j,c in enumerate(list(df.columns)):\n",
    "    if c ==  \"Calories\":     \n",
    "        pass\n",
    "    else:    \n",
    "        n = re.compile(r\"(^\\d*\\.?\\d*)\\s(\\w+)\")     # float values\n",
    "        \n",
    "        ### changing Na for 0's, to go back change 0 to np.nan\n",
    "        num = np.array([float(n.findall(i)[0][0]) if isinstance(i,str) else 0 for i in df[c].values])\n",
    "        mes = np.array([n.findall(i)[0][1] if isinstance(i,str) else 'g' for i in df[c].values])\n",
    "\n",
    "        # messurements\n",
    "        mask_mg = (mes == 'mg')/10\n",
    "        mask_mcg = (mes == \"mcg\")/10000\n",
    "        mask_g = (mes == \"g\")*.01\n",
    "        mask = mask_mg + mask_mcg +mask_g\n",
    "        mask += (mask==0)*-1\n",
    "\n",
    "        if sum(mask < 0) >1 :\n",
    "            df[c] = num/100\n",
    "        else:\n",
    "            df[c] = num*mask\n",
    "\n",
    "df[\"Vitamin A\"] *= 0.6/1000000\n",
    "df[\"Vitamin D\"] *= 0.025/1000000\n",
    "\n",
    "vitamins=['Choline','Niacin','Pantothenic acid','Riboflavin','Thiamin',\n",
    "          'Vitamin A','Vitamin B12','Vitamin B6','Vitamin C','Vitamin D','Vitamin E','Vitamin K']\n",
    "minerals = ['Calcium, Ca','Copper, Cu','Iron, Fe',    'Magnesium, Mg',\n",
    "            'Manganese, Mn','Phosphorus, P','Potassium, K','Selenium, Se','Sodium, Na','Zinc, Zn']\n",
    "# append new features\n",
    "df['Vitamins'] = df[vitamins].sum(axis=1)\n",
    "df['Minerals'] = df[minerals].sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that both data sets are clean and contain featured columns, we begin the merging process to produce a giant sparse dataframe where the rows are recipies and the columns are ingredient's (ing) nutritional properties for all ingredients. example:  \n",
    "\n",
    "|recipe|ing1_calories |ing1_protein |ing1_vitamins |... | ing1_minerals| ing2_calores| ...|total_calories|...|total_minerals|\n",
    "|-|-|-|-|-|-|-|-|-|-|-|\n",
    "\n",
    "\n",
    "In the transition to one data frame we encountered one of our biggest challenges thus far. We need to sort through the quantities of each ingredient and convert them to grams. Unfortunately, we have not found a comprehensive list of food densities online, and the measurements are not consistent on the recipe website. We have created a temporal solution that converts abstract measurements into the equivalent in grams for the most used ingredient and we map words that mean the same things to a uniform name (ex: tbs, tablesp, TBS -> tablespoon, See appendix for code).\n",
    "\n",
    "Small Example of unit converter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u contains uniform words\n",
    "conv = {c:[] for c in set(u.values())}\n",
    "# g/ units\n",
    "conv['gram'] = 1\n",
    "conv['liter'] = 1000\n",
    "conv[\"gallon\"] = 0.00026417205\n",
    "conv['lbs'] = 453.592\n",
    "conv['milliliter'] = 1\n",
    "conv['oz']= 28.34\n",
    "conv['kilogram'] = 1000\n",
    "conv['tablespoon'] = 14.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are continually searching for a solution to the conversion problem. Nevertheless, We proceed with the analysis so that when an improvement to this method is found we can get better results. \n",
    "\n",
    "There are multiple steps to build what we are calling \"Hefty_df\". For each recipe we find the ingredients it requires and look up the units and quantities. For the quantities we built a function that takes in strings of the form \"1/2 ,5 3/2, None\" and returns its float equivalent or 1 for None (it represents \"whole\"). This ingredient is found in our ingredients/nutrional value dataframe by the Levenshtein distance which compares the similarity of words by comparing how many edits are needed to change one word into the other. For example by adding or dropping a letter.  We then multiply the quantity, unit (using our unit converter), and the nutritional value of the ingredient and place them into hefty_df. Lastly, we sum the values of each property and enter it into the \"total_(respective property)\" and repeat the process (*see apendix for code).\n",
    "\n",
    "# INSERT PICTURE OF HEAD OF HEFTY\n",
    "\n",
    "The reason we built this sparse dataframe is for the intends and purposes of next semester. We use the columns with the total nutritional values columns and the ingredients/nutritional value dataframe for our analyzis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PROTEIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an important distinction between the different fat values printed on a produce. Our body needs the good fats (\"Polyunsaturated fatty acids\" and \"Monounsaturated fatty acids\") and could go without the bad ones (\"Saturated fatty acids\" and \"Trans fats\"). We wish to find out how recipe styles vary in their \"good fat to bad fat\" ratio. It is important to note that these are not true for just one ingredient (ex: fish, chicke, asparagus,etc.) or a single recipe, rather and combination of many recipies of that kind.\n",
    "\n",
    "First we will look at the recipes with high good/bad ratio:\n",
    "\n",
    "![](goodbad1.png)\n",
    "\n",
    "These are the recipies that would be recommended if someone put the constraint to have more good fats rather than bad. These results look resonable since they all tend to have leaner meet and/or recipes that are considered \"healthier\".\n",
    "\n",
    "We chose to remove the following categories From the graph above:\n",
    "- Alchoholic beverage - Most of the ingredients are not well represented since they are too specific and were put in the \"other\" ingredients pile\n",
    "- Jam - Likely there are low leves of fat which would make the ratio extreme depending on one or two recipes\n",
    "- Dog Buiscuits - The reader can know that they are good for their dog \n",
    "\n",
    "Likewise, you might want to know which recipies to abstain from making/eating to stay healthy. The following figure shows the lowest ratios of good to bad fat. \n",
    "\n",
    "![](goodbad2.png)\n",
    "\n",
    "Once again we have values that we expect like cake, pasta, and breakfast foods. Asparagus is on there because it is often cooked with butter, cheese or oils. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vitamins and Minerals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last question we would like to address is whether there is any correlation between protein, vitamins, and minerals in our list of ingredients. If so then we know that choosing one high nutritious ingredient will provide a balance more balance to your diet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](corr_m.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest correlation is between protein and Minerals which makes sense since there is iron in meat, and the lowest is between vitamins and minerals - Probably the reason they are sold seperately as supplements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Quality and Robustness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualization and Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for hefty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing units by hand (only first time seen)\n",
    "u = dict()\n",
    "for i,rec in enumerate(neal_df[mask].values):\n",
    "    for j,mes in enumerate(rec):\n",
    "        if mes in u:\n",
    "            pass\n",
    "        else:\n",
    "            print(neal_df[mask].columns[j])\n",
    "            print(mes)\n",
    "            u[mes] = input()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Conversion dictionary\n",
    "# g/ units\n",
    "conv['gram'] = 1\n",
    "conv['liter'] = 1000\n",
    "conv[\"gallon\"] = 0.00026417205\n",
    "conv['lbs'] = 453.592\n",
    "conv['milliliter'] = 1\n",
    "conv['oz']= 28.34\n",
    "conv['kilogram'] = 1000\n",
    "conv['tablespoon'] = 14.3\n",
    "conv['teaspoon'] = 4.77\n",
    "conv[\"cup\"] = 201\n",
    "conv[\"ear\"] = 92\n",
    "conv['clove'] = 7\n",
    "conv['pinch'] = 0.36\n",
    "conv['quart'] = 946.353\n",
    "conv['pint'] = 473.176\n",
    "conv['envelope'] = 7.085\n",
    "conv['None'] = 0\n",
    "conv['dash'] = 0.72\n",
    "conv['head'] = 539\n",
    "conv['stick'] = 113\n",
    "conv['package'] = 7.085\n",
    "conv['small'] = 75\n",
    "conv['medium'] = 150\n",
    "conv['large'] = 225\n",
    "conv['stalk'] = 50\n",
    "conv['strip'] = 10\n",
    "conv['square'] = 13\n",
    "conv['square'] = 56.7\n",
    "conv['box'] = 382.59\n",
    "conv['whole'] = 100\n",
    "conv['bag'] = 453.59\n",
    "conv['sprig'] = 30\n",
    "conv['bulb'] = 30\n",
    "conv['slice'] = 5\n",
    "conv['bunch'] = 120\n",
    "conv['part'] = 1\n",
    "conv['cube'] = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets mask for ingredients\n",
    "col = list(neal_df.columns) \n",
    "mask_class = np.array([i for i in col if i[:6] == \"class_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the columns for Hefty\n",
    "hefty_columns = [nut_element+\"_\"+category[6:] for category in mask_class for nut_element in df.columns]\n",
    "hefty_columns += [\"Total \"+ nut_element for nut_element in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning strings to floats\n",
    "def st_to_fl(s):\n",
    "    try:\n",
    "        # This implied \"Whole\"\n",
    "        if s is None:\n",
    "            return 1\n",
    "        # other wise make it float\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        #if error do this\n",
    "        return float(sum(Fraction(c) for c in s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building hefty\n",
    "hefty_df = pd.DataFrame(columns=hefty_columns)\n",
    "num_recipies = len(list(neal_df.index))\n",
    "\n",
    "# for each recipe\n",
    "for num, recipe in enumerate(neal_df.index):\n",
    "    # get all the entries and get the values that are not None\n",
    "    r = neal_df.iloc[recipe]\n",
    "    r_contents = r[mask_class].values != None # mask\n",
    "    \n",
    "    #get the values where it wasn't none and inicialize the row\n",
    "    ingredients = r[mask_class][r_contents].values\n",
    "    hefty_df.loc[len(hefty_df)] = 0\n",
    "    \n",
    "    #progress bar\n",
    "    if num% 200 == 0:\n",
    "        print(f\"{num/num_recipies}%\")\n",
    "        \n",
    "    # for each ingredient in the recipe\n",
    "    for ing in ingredients:\n",
    "        # change the quantity to float and convert units to grams\n",
    "        quantity = st_to_fl(r['quant_' + ing])\n",
    "        unit_factor = conv[r['unit_' + ing]]\n",
    "        conversion = quantity*unit_factor  \n",
    "        \n",
    "        #find the most similar ingredient in the nutrition data frame\n",
    "        most_similar_ing = process.extractOne(ing,df.index)[0]\n",
    "        \n",
    "        # match the columns of hefty with the ingredient\n",
    "        col = list(hefty_df.columns) \n",
    "        hefty_mask = np.array([i for i in col if i[-(len(ing)+1):] == \"_\"+ing])\n",
    "        \n",
    "        # for each column with the ingredient mutiply nutrition value by conversion\n",
    "        # and add to total column\n",
    "        for m,i,c in zip(hefty_mask, df.loc[most_similar_ing].values,df.columns):\n",
    "            value = i*conversion\n",
    "            hefty_df.loc[num][m] = value\n",
    "            hefty_df.loc[num][\"Total \" + c] += value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
